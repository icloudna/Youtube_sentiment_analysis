{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Khaiii_SkipGram_GRU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4pZySJvIKcU"
      },
      "source": [
        "# Train Data Preprocessing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh4qrbblqv0_"
      },
      "source": [
        "## 1) Importing Libraries & Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bTr94VQpsHL4"
      },
      "source": [
        "#### (1) importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyfAHDmQtyAT"
      },
      "source": [
        "!git clone https://github.com/kakao/khaiii.git\n",
        "!pip install cmake\n",
        "!mkdir build\n",
        "!cd build && cmake /content/khaiii\n",
        "!cd /content/build/ && make all\n",
        "!cd /content/build/ && make resource\n",
        "!cd /content/build && make install\n",
        "!cd /content/build && make package_python\n",
        "!pip install /content/build/package_python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "349azimIxHIb"
      },
      "source": [
        "from khaiii import KhaiiiApi\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jbM3iS8sMkZ"
      },
      "source": [
        "#### (2) Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6P-vyomr-Pr",
        "outputId": "fa51fc60-4ac4-4add-f8dc-47e1ae0922c4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fhjsti79wvpJ"
      },
      "source": [
        "X_train=pd.read_csv(\"/content/drive/Shareddrives/20-2 KUBIG 자연어처리 프로젝트/최종 트레이닝데이터/x_train.csv\")\n",
        "y_train=pd.read_csv(\"/content/drive/Shareddrives/20-2 KUBIG 자연어처리 프로젝트/최종 트레이닝데이터/y_train.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0gjDOYCsfXe"
      },
      "source": [
        "#### (3) Check Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sHNzClHzQ3u",
        "outputId": "0513bda2-87b6-4c00-a9e3-e609ae81c085"
      },
      "source": [
        "X_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>document</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>평점에 스포 달린 영화는 무조건 점</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>재밌습니다 잘 만든 영화라는</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>딱 점</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>만남과 헤어짐 그리고 재회</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>롱기스트 야드를 먼저 봐서 그런지 진짜 쓰레기 특히 주인공 진짜 맘에 안 든다</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0                                     document\n",
              "0           0                          평점에 스포 달린 영화는 무조건 점\n",
              "1           1                              재밌습니다 잘 만든 영화라는\n",
              "2           2                                          딱 점\n",
              "3           3                               만남과 헤어짐 그리고 재회\n",
              "4           4  롱기스트 야드를 먼저 봐서 그런지 진짜 쓰레기 특히 주인공 진짜 맘에 안 든다"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "433bdXkUsrhE"
      },
      "source": [
        "#### (4) Morpheme Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjXcNNtRILVS"
      },
      "source": [
        "api = KhaiiiApi()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYtCkOYYXSmH"
      },
      "source": [
        "significant_tags = ['NNG', 'NNP', 'NNB', 'VV', 'VA', 'VX', 'MAG', 'MAJ', 'XSV', 'XSA']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSAPL3XnXego"
      },
      "source": [
        "def pos_text(texts):\n",
        "    corpus = []\n",
        "    for sent in texts:\n",
        "        pos_tagged = ''\n",
        "        for word in api.analyze(sent):\n",
        "            for morph in word.morphs:\n",
        "                if morph.tag in significant_tags:\n",
        "                    pos_tagged += morph.lex + '/' + morph.tag + ' '\n",
        "        corpus.append(pos_tagged.strip())\n",
        "    return corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58jXkjumaxh_"
      },
      "source": [
        "tagged_corpus=pos_text(X_train[\"document\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVhotns6bAdv"
      },
      "source": [
        "p1 = re.compile('[가-힣A-Za-z0-9]+/NN. [가-힣A-Za-z0-9]+/XS.')\n",
        "p2 = re.compile('[가-힣A-Za-z0-9]+/NN. [가-힣A-Za-z0-9]+/XSA [가-힣A-Za-z0-9]+/VX')\n",
        "p3 = re.compile('[가-힣A-Za-z0-9]+/VV')\n",
        "p4 = re.compile('[가-힣A-Za-z0-9]+/VX')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gLq6CODVrOx0"
      },
      "source": [
        "## 2) Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XwKabGheYF36"
      },
      "source": [
        "#### (1) Stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiQvOQ5ybJKw"
      },
      "source": [
        "def stemming_text(text):\n",
        "    corpus = []\n",
        "    for sent in text:\n",
        "        ori_sent = sent\n",
        "        mached_terms = re.findall(p1, ori_sent)\n",
        "        for terms in mached_terms:\n",
        "            ori_terms = terms\n",
        "            modi_terms = ''\n",
        "            for term in terms.split(' '):\n",
        "                lemma = term.split('/')[0]\n",
        "                tag = term.split('/')[-1]\n",
        "                modi_terms += lemma\n",
        "            modi_terms += '다/VV'\n",
        "            ori_sent = ori_sent.replace(ori_terms, modi_terms)\n",
        "        \n",
        "        mached_terms = re.findall(p2, ori_sent)\n",
        "        for terms in mached_terms:\n",
        "            ori_terms = terms\n",
        "            modi_terms = ''\n",
        "            for term in terms.split(' '):\n",
        "                lemma = term.split('/')[0]\n",
        "                tag = term.split('/')[-1]\n",
        "                if tag != 'VX':\n",
        "                    modi_terms += lemma\n",
        "            modi_terms += '다/VV'\n",
        "            ori_sent = ori_sent.replace(ori_terms, modi_terms)\n",
        "\n",
        "        mached_terms = re.findall(p3, ori_sent)\n",
        "        for terms in mached_terms:\n",
        "            ori_terms = terms\n",
        "            modi_terms = ''\n",
        "            for term in terms.split(' '):\n",
        "                lemma = term.split('/')[0]\n",
        "                tag = term.split('/')[-1]\n",
        "                modi_terms += lemma\n",
        "            if '다' != modi_terms[-1]:\n",
        "                modi_terms += '다'\n",
        "            modi_terms += '/VV'\n",
        "            ori_sent = ori_sent.replace(ori_terms, modi_terms)\n",
        "\n",
        "        mached_terms = re.findall(p4, ori_sent)\n",
        "        for terms in mached_terms:\n",
        "            ori_terms = terms\n",
        "            modi_terms = ''\n",
        "            for term in terms.split(' '):\n",
        "                lemma = term.split('/')[0]\n",
        "                tag = term.split('/')[-1]\n",
        "                modi_terms += lemma\n",
        "            if '다' != modi_terms[-1]:\n",
        "                modi_terms += '다'\n",
        "            modi_terms += '/VV'\n",
        "            ori_sent = ori_sent.replace(ori_terms, modi_terms)\n",
        "        corpus.append(ori_sent)\n",
        "    return corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8LEA5kx5bd4i"
      },
      "source": [
        "stemming_corpus = stemming_text(tagged_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTHVy9F7bmJS",
        "outputId": "1c2ba3f7-a524-44c0-ae24-6f02d18b6c73"
      },
      "source": [
        "for i in range(0, 30):\n",
        "    print(stemming_corpus[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "평점/NNG 스포/NNG 달리다/VV 영화/NNG 무조건/MAG 점/NNG\n",
            "재미있/VA 잘/MAG 만들다/VV 영화/NNG\n",
            "딱/MAG 점/NNG\n",
            "만남/NNG 헤어지다/VV 그리고/MAJ 재회/NNG\n",
            "롱/NNG 기스트/NNP 야/NNG 드/NNP 먼저/MAG 보다/VV 그렇/VA 진짜/NNG 쓰레기/NNG 특히/MAG 주인공/NNG 진짜/NNG 맘/NNG 안/MAG 들다/VV\n",
            "오늘/NNG 고지전/NNG 다시/MAG 보다/VV 나라/NNG 위하다/VV 휴전/NNG 직전/NNG 싸우다/VV 전사하다/VV 참전/NNG 용사/NNG 감사/NNG 드다/VV 리/XSV\n",
            "술/NNG 담배/NNG 더/MAG 해롭/VA 것/NNB 막장/NNG 드라마/NNG\n",
            "정말/MAG 좋/VA 특히/MAG 영상/NNG 음악/NNG\n",
            "ㅡ/NNP\n",
            "예고편/NNG 낚이다/VV 최악/NNG 영화/NNG 중/NNB\n",
            "현실/NNG 재밌/VA\n",
            "하/XSA 영화/NNG 만들다/VV 내다/VV 수/NNB 없/VA 구로/NNP 사와/NNG 재능/NNG\n",
            "우/MAG 굳ㅋ/MAG 재미/NNG 있/VA\n",
            "쩌르다/VV 진짜/MAG 국영/NNG 형/NNG 최고/NNG\n",
            "쓰레기/NNG 영화/NNG 다/MAG 있다/VV 인물/NNG 관계/NNG 정리/NNG 안/MAG 하다/VV 주다/VV 줄거리/NNG 없/VA 내용/NNG ㅉ/NNG\n",
            "무섭/VA 오페라/NNG 유령/NNG 프레데/NNP 터/NNG\n",
            "결혼하다/VV 보다/VV 미혼/NNG 때/NNG 또/MAG 감동/NNG 받다/VV 영화/NNG\n",
            "캐서린/NNP 제타/NNG 존스/NNP 보톡스/NNG 자연스럽다/VV 영화/NNG 마치/MAG 전성기/NNG 훨씬/MAG 지나다/VV 톱스타/NNG 뒤늦/VA 공연/NNG 하다/VV 듯하다/VV 느낌/NNG 마디/NNG 철/NNG 지나다/VV 급/NNG 액션/NNG\n",
            "이상하다/VV 것/NNB 만들다/VV 것/NNB 왠지/MAG 시간/NNG 지나다/VV 허접하다/VV 지다/VV\n",
            "드라마/NNG 재밌/VA 보다/VV 것/NNB 없/VA 것/NNB 같/VA 구다/VV\n",
            "결말/NNG 좀/MAG 슬프/VA 다/MAG 전두엽/NNG 수순/NNG 끝내/MAG 받다/VV 맥머피/NNG 이제/NNG 예전/NNG 맥머피/NNG 어쩌다/VV 수/NNB 없이/MAG 치프/NNG 죽이다/VV 주다/VV 영혼/NNG 탈출/NNG 시도하다/VV 하다/VV 거/NNB 같/VA 빌리/NNP 맥머피/NNG 죽음/NNG 정말/MAG 값지/VA 죽음/NNG 비치다/VV\n",
            "우리나라/NNG 스타일/NNG\n",
            "신/NNG 눈빛/NNG 연기/NNG 그리고/MAJ 규원/NNP 춤/NNG 노래/NNG 연기/NNG 모두/MAG 잘/MAG 소화하다/VV 내다/VV 잘/MAG 보다/VV\n",
            "망하다/VV 망하다/VV 망/VA 망했/NNG 망다/VV 하/XSV\n",
            "개명/NNG 직/NNG 것/NNB 바로/MAG\n",
            "여주인공/NNG 버서/NNP 점/NNG 드리다/VV 좀비/MAG 영화/NNG 보다/VV 것/NNB\n",
            "말/NNG 형용하다/VV 수/NNB 없/VA 이렇/VA 때하다/VV 표현/NNG\n",
            "준석이/NNP 동/NNP 수/NNG 작업/NNG 지시하다/VV 거/NNB 맞다/VV 죽다/VV 하다/VV 않다/VV 겁다/VV 불구/NNG 만들다/VV 작업/NNG 나오다/VV 그리고/MAJ 하와이/NNG 가다/VV 것/NNB 권하다/VV 거절당하다/VV 나오다/VV 때/NNG 동수/NNG 부하/NNG 칼/NNG 들다/VV 작업하다/VV 것/NNB 동수/NNP 아버지/NNG 제사/NNG 다/MAG 하다/VV 보내다/VV 주다/VV 동수/NNP 공항/NNG 가리다/VV 죽다/VV\n",
            "상처/NNG 받다/VV 영혼/NNG 피맺히다/VV 복수극/NNG 그냥/MAG 그런대로/MAG 보다/VV 만/NNB 하다/VV 확실히/MAG 떨어지다/VV 보이다/VV 것/NNB 어쩌다/VV 수/NNB 없/VA\n",
            "굿/NNG 재밌/VA 것/NNB 제보/NNG 다/VV 역/NNG 쉬하/NNG 원/NNB 임창정/NNP ㅎ/NNG ㅎ/NNG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-YrVuCC5PIw"
      },
      "source": [
        "def text_cleaning(text):\n",
        "   hangul=re.compile(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]+\")\n",
        "   result=hangul.sub('', text)\n",
        "   return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "emiO4xr77duM"
      },
      "source": [
        "for sent in stemming_corpus:\n",
        "  map(text_cleaning, sent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8czzpSpP8UcD"
      },
      "source": [
        "corpus=[]\n",
        "for i in range(0, len(stemming_corpus)):\n",
        "  corpus.append(text_cleaning(stemming_corpus[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdrn2wnX8M5D"
      },
      "source": [
        "clean_corpus=corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TX3FH24rCMJC"
      },
      "source": [
        "corpus=[]\n",
        "for sent in clean_corpus:\n",
        "  corpus.append(sent.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oy_bDukICQS2"
      },
      "source": [
        "corpus_comma=corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmRmhK26CYQn",
        "outputId": "e73dc5f5-38ea-4a6d-9178-63121b158911"
      },
      "source": [
        "for i in range(0, 30):\n",
        "    print(corpus_comma[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['평점', '스포', '달리다', '영화', '무조건', '점']\n",
            "['재미있', '잘', '만들다', '영화']\n",
            "['딱', '점']\n",
            "['만남', '헤어지다', '그리고', '재회']\n",
            "['롱', '기스트', '야', '드', '먼저', '보다', '그렇', '진짜', '쓰레기', '특히', '주인공', '진짜', '맘', '안', '들다']\n",
            "['오늘', '고지전', '다시', '보다', '나라', '위하다', '휴전', '직전', '싸우다', '전사하다', '참전', '용사', '감사', '드다', '리']\n",
            "['술', '담배', '더', '해롭', '것', '막장', '드라마']\n",
            "['정말', '좋', '특히', '영상', '음악']\n",
            "['ㅡ']\n",
            "['예고편', '낚이다', '최악', '영화', '중']\n",
            "['현실', '재밌']\n",
            "['하', '영화', '만들다', '내다', '수', '없', '구로', '사와', '재능']\n",
            "['우', '굳ㅋ', '재미', '있']\n",
            "['쩌르다', '진짜', '국영', '형', '최고']\n",
            "['쓰레기', '영화', '다', '있다', '인물', '관계', '정리', '안', '하다', '주다', '줄거리', '없', '내용', 'ㅉ']\n",
            "['무섭', '오페라', '유령', '프레데', '터']\n",
            "['결혼하다', '보다', '미혼', '때', '또', '감동', '받다', '영화']\n",
            "['캐서린', '제타', '존스', '보톡스', '자연스럽다', '영화', '마치', '전성기', '훨씬', '지나다', '톱스타', '뒤늦', '공연', '하다', '듯하다', '느낌', '마디', '철', '지나다', '급', '액션']\n",
            "['이상하다', '것', '만들다', '것', '왠지', '시간', '지나다', '허접하다', '지다']\n",
            "['드라마', '재밌', '보다', '것', '없', '것', '같', '구다']\n",
            "['결말', '좀', '슬프', '다', '전두엽', '수순', '끝내', '받다', '맥머피', '이제', '예전', '맥머피', '어쩌다', '수', '없이', '치프', '죽이다', '주다', '영혼', '탈출', '시도하다', '하다', '거', '같', '빌리', '맥머피', '죽음', '정말', '값지', '죽음', '비치다']\n",
            "['우리나라', '스타일']\n",
            "['신', '눈빛', '연기', '그리고', '규원', '춤', '노래', '연기', '모두', '잘', '소화하다', '내다', '잘', '보다']\n",
            "['망하다', '망하다', '망', '망했', '망다', '하']\n",
            "['개명', '직', '것', '바로']\n",
            "['여주인공', '버서', '점', '드리다', '좀비', '영화', '보다', '것']\n",
            "['말', '형용하다', '수', '없', '이렇', '때하다', '표현']\n",
            "['준석이', '동', '수', '작업', '지시하다', '거', '맞다', '죽다', '하다', '않다', '겁다', '불구', '만들다', '작업', '나오다', '그리고', '하와이', '가다', '것', '권하다', '거절당하다', '나오다', '때', '동수', '부하', '칼', '들다', '작업하다', '것', '동수', '아버지', '제사', '다', '하다', '보내다', '주다', '동수', '공항', '가리다', '죽다']\n",
            "['상처', '받다', '영혼', '피맺히다', '복수극', '그냥', '그런대로', '보다', '만', '하다', '확실히', '떨어지다', '보이다', '것', '어쩌다', '수', '없']\n",
            "['굿', '재밌', '것', '제보', '다', '역', '쉬하', '원', '임창정', 'ㅎ', 'ㅎ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt9H31Y3YL_W"
      },
      "source": [
        "#### (2) Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny5jQTj0b1zO"
      },
      "source": [
        "path=\"/content/drive/Shareddrives/20-2 KUBIG 자연어처리 프로젝트/korean_stopwords.txt\"\n",
        "with open(path, encoding='utf-8') as f:\n",
        "  stopwords=f.readlines()\n",
        "stopwords=[x.strip() for x in stopwords]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riw_TfglDJgo"
      },
      "source": [
        "corpus=[]\n",
        "for sentence in corpus_comma:\n",
        "    temp_X = [word for word in sentence if not word in stopwords]\n",
        "    corpus.append(temp_X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zip7Nv-dY-z"
      },
      "source": [
        "removed_stopword_corpus = corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSi0XG8hdc3J",
        "outputId": "ad655cac-18cf-43da-80f6-cb4c8e0536e6"
      },
      "source": [
        "for i in range(0, 30):\n",
        "    print(removed_stopword_corpus[i])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['평점', '스포', '달리다', '영화', '무조건', '점']\n",
            "['재미있', '잘', '만들다', '영화']\n",
            "['점']\n",
            "['만남', '헤어지다', '재회']\n",
            "['롱', '기스트', '드', '먼저', '보다', '그렇', '진짜', '쓰레기', '특히', '주인공', '진짜', '맘', '안', '들다']\n",
            "['오늘', '고지전', '다시', '보다', '나라', '위하다', '휴전', '직전', '싸우다', '전사하다', '참전', '용사', '감사', '드다', '리']\n",
            "['술', '담배', '더', '해롭', '막장', '드라마']\n",
            "['정말', '좋', '특히', '영상', '음악']\n",
            "['ㅡ']\n",
            "['예고편', '낚이다', '최악', '영화', '중']\n",
            "['현실', '재밌']\n",
            "['영화', '만들다', '내다', '수', '없', '구로', '사와', '재능']\n",
            "['우', '굳ㅋ', '재미', '있']\n",
            "['쩌르다', '진짜', '국영', '형', '최고']\n",
            "['쓰레기', '영화', '다', '인물', '관계', '정리', '안', '하다', '주다', '줄거리', '없', '내용', 'ㅉ']\n",
            "['무섭', '오페라', '유령', '프레데', '터']\n",
            "['결혼하다', '보다', '미혼', '감동', '받다', '영화']\n",
            "['캐서린', '제타', '존스', '보톡스', '자연스럽다', '영화', '전성기', '지나다', '톱스타', '뒤늦', '공연', '하다', '듯하다', '느낌', '마디', '철', '지나다', '급', '액션']\n",
            "['이상하다', '만들다', '왠지', '지나다', '허접하다', '지다']\n",
            "['드라마', '재밌', '보다', '없', '같', '구다']\n",
            "['결말', '슬프', '다', '전두엽', '수순', '끝내', '받다', '맥머피', '이제', '예전', '맥머피', '어쩌다', '수', '없이', '치프', '죽이다', '주다', '영혼', '탈출', '시도하다', '하다', '거', '같', '빌리', '맥머피', '죽음', '정말', '값지', '죽음', '비치다']\n",
            "['우리나라', '스타일']\n",
            "['신', '눈빛', '연기', '규원', '춤', '노래', '연기', '잘', '소화하다', '내다', '잘', '보다']\n",
            "['망하다', '망하다', '망', '망했', '망다']\n",
            "['개명', '직']\n",
            "['여주인공', '버서', '점', '드리다', '좀비', '영화', '보다']\n",
            "['말', '형용하다', '수', '없', '이렇', '때하다', '표현']\n",
            "['준석이', '동', '수', '작업', '지시하다', '거', '맞다', '죽다', '하다', '않다', '겁다', '불구', '만들다', '작업', '나오다', '하와이', '가다', '권하다', '거절당하다', '나오다', '동수', '부하', '칼', '들다', '작업하다', '동수', '아버지', '제사', '다', '하다', '보내다', '주다', '동수', '공항', '가리다', '죽다']\n",
            "['상처', '받다', '영혼', '피맺히다', '복수극', '그냥', '그런대로', '보다', '만', '하다', '확실히', '떨어지다', '보이다', '어쩌다', '수', '없']\n",
            "['굿', '재밌', '제보', '다', '역', '쉬하', '원', '임창정', 'ㅎ', 'ㅎ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWTiCJZQclTR",
        "outputId": "c31afdab-3be8-45e2-fdee-6b20675a3761"
      },
      "source": [
        "len(removed_stopword_corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "99438"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyrtCh_FrZxU"
      },
      "source": [
        "## 3) Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRlho884-3TD"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "model = Word2Vec(sentences=removed_stopword_corpus, size=200, window=5, min_count=3, workers=4, sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0urZVJzDDvXB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c4140a6-9237-4cb3-d1a0-403674acdf96"
      },
      "source": [
        "model.wv.vectors.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15542, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7ouK4cLyuyY"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMUUFJDeyv7I",
        "outputId": "017e3a4a-2c6d-4659-a9df-4527d67cdf62"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(removed_stopword_corpus)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "44701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2anEEQN1y-rF",
        "outputId": "34b1fe54-8f25-4c48-b646-30863ac6b35f"
      },
      "source": [
        "X_encoded = t.texts_to_sequences(removed_stopword_corpus)\n",
        "print(X_encoded[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[25, 2239, 776, 1, 651, 17], [20, 21, 16, 1], [17], [1895, 1653, 5514], [2780, 21548, 288, 749, 2, 84, 24, 49, 225, 98, 24, 346, 10, 61], [317, 15543, 54, 2, 460, 145, 12520, 3192, 614, 12521, 9293, 9294, 1654, 1218, 123], [1534, 1655, 28, 21549, 212, 33], [8, 6, 225, 206, 144], [121], [743, 495, 86, 1, 39]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy2W_CD3zGfo",
        "outputId": "3795ec31-23fd-4f33-983d-688400e6892b"
      },
      "source": [
        "max_len=max(len(l) for l in X_encoded)\n",
        "print(max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "66\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0PM-88qzKEW",
        "outputId": "6dd3e074-9429-43cc-de53-6d8463c9ca2c"
      },
      "source": [
        "X_train=pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "y_train=np.array(y_train)\n",
        "print(X_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   25  2239   776 ...     0     0     0]\n",
            " [   20    21    16 ...     0     0     0]\n",
            " [   17     0     0 ...     0     0     0]\n",
            " ...\n",
            " [10343  3498  1864 ...     0     0     0]\n",
            " [ 5904   369     2 ...     0     0     0]\n",
            " [  526   220     2 ...     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iH2t3HREzVwh"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_size, 200))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJvDGTMtzoV0"
      },
      "source": [
        "def get_vector(word):\n",
        "    if word in model:\n",
        "        return model[word]\n",
        "    else:\n",
        "        return None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHV5rjm0zvQ2",
        "outputId": "fddd42ff-a3d2-480c-b47a-1cc233bf5827"
      },
      "source": [
        "for word, i in t.word_index.items(): \n",
        "    temp = get_vector(word) \n",
        "    if temp is not None: \n",
        "        embedding_matrix[i] = temp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtRQgUpJTJX5"
      },
      "source": [
        "# 4) Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "026VTrCASgym"
      },
      "source": [
        "from tensorflow.keras.layers import Embedding, Dense, GRU, Dropout\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isrDmyDWTQP5"
      },
      "source": [
        "model = Sequential()\n",
        "e = Embedding(vocab_size, 200, weights=[embedding_matrix], input_length=max_len, trainable=False)\n",
        "model.add(e)\n",
        "model.add(GRU(128))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n",
        "mc = ModelCheckpoint('best_model', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUErQXGMbFNa",
        "outputId": "ad70fefc-6cfc-42ea-9c41-66b14ae0a9e1"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=15, callbacks=[es, mc], batch_size=60, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1326/1326 [==============================] - ETA: 0s - loss: 0.6933 - acc: 0.4996\n",
            "Epoch 00001: val_acc improved from -inf to 0.50096, saving model to best_model\n",
            "1326/1326 [==============================] - 183s 138ms/step - loss: 0.6933 - acc: 0.4996 - val_loss: 0.6931 - val_acc: 0.5010\n",
            "Epoch 2/15\n",
            "1326/1326 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.5024\n",
            "Epoch 00002: val_acc did not improve from 0.50096\n",
            "1326/1326 [==============================] - 178s 134ms/step - loss: 0.6932 - acc: 0.5024 - val_loss: 0.6933 - val_acc: 0.5010\n",
            "Epoch 3/15\n",
            "1326/1326 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.5018\n",
            "Epoch 00003: val_acc did not improve from 0.50096\n",
            "1326/1326 [==============================] - 173s 131ms/step - loss: 0.6932 - acc: 0.5018 - val_loss: 0.6932 - val_acc: 0.5010\n",
            "Epoch 4/15\n",
            "1326/1326 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.5021\n",
            "Epoch 00004: val_acc did not improve from 0.50096\n",
            "1326/1326 [==============================] - 176s 132ms/step - loss: 0.6932 - acc: 0.5021 - val_loss: 0.6931 - val_acc: 0.5010\n",
            "Epoch 5/15\n",
            "1326/1326 [==============================] - ETA: 0s - loss: 0.6932 - acc: 0.4980\n",
            "Epoch 00005: val_acc did not improve from 0.50096\n",
            "1326/1326 [==============================] - 171s 129ms/step - loss: 0.6932 - acc: 0.4980 - val_loss: 0.6932 - val_acc: 0.5010\n",
            "Epoch 00005: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58aF1AdKDBQl"
      },
      "source": [
        "# 5) Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Zut5YahxDt7k",
        "outputId": "a68ba150-8645-4e99-f4e7-4138889d2d05"
      },
      "source": [
        "test= pd.read_csv(\"/content/drive/Shareddrives/20-2 KUBIG 자연어처리 프로젝트/Test_Real_final.csv\")\n",
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>굳 ㅋ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>뭐 야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>지루하지는 않은데 완전 막장 임 돈 주고 보기에는</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>만 아니었어도 별 다섯 개 줬을 텐데 왜 로 나와서 제 심기를 불편하게 하죠</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                           0\n",
              "0      1                                         굳 ㅋ\n",
              "1      0                                         NaN\n",
              "2      0           뭐 야 이 평점들은 나쁘진 않지만 점 짜리는 더더욱 아니잖아\n",
              "3      0                 지루하지는 않은데 완전 막장 임 돈 주고 보기에는\n",
              "4      0  만 아니었어도 별 다섯 개 줬을 텐데 왜 로 나와서 제 심기를 불편하게 하죠"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz-dy_bzD1RH"
      },
      "source": [
        "test = test.dropna(how = 'any')\n",
        "tagged_corpus=pos_text(test[\"0\"])\n",
        "stemming_corpus = stemming_text(tagged_corpus)\n",
        "for sent in stemming_corpus:\n",
        "  map(text_cleaning, sent)\n",
        "corpus=[]\n",
        "for i in range(0, len(stemming_corpus)):\n",
        "  corpus.append(text_cleaning(stemming_corpus[i]))\n",
        "clean_corpus = corpus\n",
        "corpus=[]\n",
        "for sent in clean_corpus:\n",
        "  corpus.append(sent.split())\n",
        "corpus_comma=corpus\n",
        "corpus=[]\n",
        "for sentence in corpus_comma:\n",
        "    temp_X = [word for word in sentence if not word in stopwords]\n",
        "    corpus.append(temp_X)\n",
        "removed_stopword_corpus = corpus\n",
        "Test = removed_stopword_corpus\n",
        "\n",
        "model_test = Word2Vec(sentences=Test, size=100, window=5, min_count=3, workers=4, sg=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5SpXKHVRHOf"
      },
      "source": [
        "y_test=test[\"label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR933_BKRKU3",
        "outputId": "d6668573-2ae9-48b4-dd8f-67978374da40"
      },
      "source": [
        "len(y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "52244"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHcMa8wHKm9S",
        "outputId": "667721e0-442e-44e1-ebd2-a00d458de936"
      },
      "source": [
        "t = Tokenizer()\n",
        "t.fit_on_texts(Test)\n",
        "vocab_size = len(t.word_index) + 1\n",
        "print(vocab_size)\n",
        "X_encoded = t.texts_to_sequences(Test)\n",
        "print(X_encoded[:10])\n",
        "max_len=max(len(l) for l in X_encoded)\n",
        "print(max_len)\n",
        "\n",
        "X_test=pad_sequences(X_encoded, maxlen=max_len, padding='post')\n",
        "y_test=np.array(y_test)\n",
        "\n",
        "embedding_matrix = np.zeros((vocab_size, 100))\n",
        "def get_vector(word):\n",
        "    if word in model_test:\n",
        "        return model_test[word]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "for word, i in t.word_index.items(): \n",
        "    temp = get_vector(word) \n",
        "    if temp is not None: \n",
        "        embedding_matrix[i] = temp"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37744\n",
            "[[907, 23], [24, 273, 15, 20, 548, 5498, 15], [15, 79, 254, 188, 76, 8, 2], [122, 89, 8, 243, 21, 15848, 597, 3], [152, 15849, 9, 27, 152, 1], [57], [270, 302, 2505, 186, 15850, 4, 1527, 2741, 16, 3365, 2300, 3], [1042, 5499, 454, 281, 44, 4, 2397, 300, 141, 40, 10, 9, 15851, 15852, 808, 10934, 15853, 13, 1, 15854], [2869, 1263, 294, 2506, 419, 2398, 64, 2021, 26, 71, 15], [101, 4932, 122, 10935, 15855]]\n",
            "448\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vc6qqd50B66O",
        "outputId": "25bcdfbc-292d-4cc5-97f5-eb454113d499"
      },
      "source": [
        "loaded_model = load_model('best_model')\n",
        "print(\"\\n 테스트 정확도: %.4f\" % (loaded_model.evaluate(X_test, y_test)[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 66) for input Tensor(\"embedding_7_input_1:0\", shape=(None, 66), dtype=float32), but it was called on an input with incompatible shape (None, 448).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1633/1633 [==============================] - 180s 110ms/step - loss: 0.6932 - acc: 0.4875\n",
            "\n",
            " 테스트 정확도: 0.4875\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}